{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Extract entities and relationships from the following code. Return the nodes and edges in JSON format.\n",
    "\n",
    "Code :\n",
    "``` \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from KnowledgeGraph import kg\n",
    "\n",
    "class GraphEmbedding:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_node(self, node):\n",
    "        return self.model.encode(node)\n",
    "\n",
    "    def embed_graph(self, graph):\n",
    "        embeddings = {}\n",
    "        for node in graph.nodes():\n",
    "            embeddings[node] = self.embed_node(node)\n",
    "        return embeddings\n",
    "\n",
    "# Usage\n",
    "ge = GraphEmbedding()\n",
    "node_embeddings = ge.embed_graph(kg.graph)\n",
    "```\n",
    "\n",
    "Format the output as JSON with the following keys and nothing else:\n",
    "Adjacency_matrix\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Dict\n",
    "from llama_index.llms.langchain import LangChainLLM\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    tiemout = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\"Adjacency_matrix\": {\n",
      "\"GraphEmbedding\": {\n",
      "\"model\": \"SentenceTransformer\",\n",
      "\"__init__\": \"self.model\",\n",
      "\"embed_node\": \"self.model.encode(node)\",\n",
      "\"embed_graph\": {\n",
      "\"embeddings\": \"{}\",\n",
      "\"node\": \"graph.nodes()\",\n",
      "\"embeddings[node]\": \"self.embed_node(node)\"\n",
      "}\n",
      "},\n",
      "\"SentenceTransformer\": {\n",
      "\"model_name\": \"all-MiniLM-L6-v2\"\n",
      "},\n",
      "\"ge\": \"GraphEmbedding()\",\n",
      "\"node_embeddings\": \"ge.embed_graph(kg.graph)\",\n",
      "\"kg\": \"KnowledgeGraph\",\n",
      "\"kg.graph\": \"graph\",\n",
      "\"graph\": \"graph.nodes()\",\n",
      "\"node\": \"node\",\n",
      "\"embeddings\": \"{}\",\n",
      "\"self.model\": \"SentenceTransformer(model_name)\",\n",
      "\"self.model.encode(node)\": \"np.array\",\n",
      "\"np.array\": \"embeddings[node]\"\n",
      "}\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "nodes_schema = ResponseSchema(name=\"nodes\",\n",
    "                                   description=\"List of nodes\",\n",
    "                                   type=\"List\")\n",
    "\n",
    "edges_schema = ResponseSchema(name=\"edges\",\n",
    "                                   description=\"List of edges\",\n",
    "                                   type=\"List\")\n",
    "\n",
    "response_schemas = [nodes_schema, edges_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas=response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_inst = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"nodes\": List  // List of nodes\n",
      "\t\"edges\": List  // List of edges\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"\"\"\n",
    "Extract the details from the following Python code and format them as a JSON object. Each class should be a node with its methods as nodes connected by edges. Each method should have nodes for its attributes and return values. Each edge should describe the relationship between nodes.\n",
    "\n",
    "For Example:\n",
    "\n",
    "Code :\n",
    "``` \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from KnowledgeGraph import kg\n",
    "\n",
    "class GraphEmbedding:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_node(self, node):\n",
    "        return self.model.encode(node)\n",
    "\n",
    "    def embed_graph(self, graph):\n",
    "        embeddings = {}\n",
    "        for node in graph.nodes():\n",
    "            embeddings[node] = self.embed_node(node)\n",
    "        return embeddings\n",
    "\n",
    "# Usage\n",
    "ge = GraphEmbedding()\n",
    "node_embeddings = ge.embed_graph(kg.graph)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```json\n",
    "{\n",
    "  \"nodes\": [\n",
    "    {\"id\": \"1\", \"label\": \"GraphEmbedding\"},\n",
    "    {\"id\": \"2\", \"label\": \"__init__\"},\n",
    "    {\"id\": \"3\", \"label\": \"model_name\"},\n",
    "    {\"id\": \"4\", \"label\": \"model\"},\n",
    "    {\"id\": \"5\", \"label\": \"embed_node\"},\n",
    "    {\"id\": \"6\", \"label\": \"node\"},\n",
    "    {\"id\": \"7\", \"label\": \"model.encode(node)\"},\n",
    "    {\"id\": \"8\", \"label\": \"embed_graph\"},\n",
    "    {\"id\": \"9\", \"label\": \"graph\"},\n",
    "    {\"id\": \"10\", \"label\": \"embeddings\"},\n",
    "    {\"id\": \"11\", \"label\": \"graph.nodes()\"},\n",
    "    {\"id\": \"12\", \"label\": \"embed_node(node)\"}\n",
    "  ],\n",
    "  \"edges\": [\n",
    "    {\"source\": \"1\", \"target\": \"2\", \"label\": \"has method\"},\n",
    "    {\"source\": \"2\", \"target\": \"3\", \"label\": \"has parameter\"},\n",
    "    {\"source\": \"2\", \"target\": \"4\", \"label\": \"has attribute\"},\n",
    "    {\"source\": \"1\", \"target\": \"5\", \"label\": \"has method\"},\n",
    "    {\"source\": \"5\", \"target\": \"6\", \"label\": \"has parameter\"},\n",
    "    {\"source\": \"5\", \"target\": \"7\", \"label\": \"returns\"},\n",
    "    {\"source\": \"1\", \"target\": \"8\", \"label\": \"has method\"},\n",
    "    {\"source\": \"8\", \"target\": \"9\", \"label\": \"has parameter\"},\n",
    "    {\"source\": \"8\", \"target\": \"10\", \"label\": \"has attribute\"},\n",
    "    {\"source\": \"8\", \"target\": \"11\", \"label\": \"has attribute\"},\n",
    "    {\"source\": \"8\", \"target\": \"12\", \"label\": \"returns\"}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Given Code:\n",
    "\n",
    "```\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "\n",
    "class KnowledgeGraph:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.Graph()\n",
    "\n",
    "    def add_entity(self, entity):\n",
    "        self.graph.add_node(entity)\n",
    "\n",
    "    def add_relationship(self, entity1, entity2, relationship):\n",
    "        self.graph.add_edge(entity1, entity2, relationship=relationship)\n",
    "\n",
    "    def visualize(self, filename='graph.html'):\n",
    "        net = Network(notebook=False)\n",
    "        net.from_nx(self.graph)\n",
    "        net.show(filename, notebook=False)\n",
    "\n",
    "    def save(self, filename='knowledge_graph.json'):\n",
    "        data = nx.node_link_data(self.graph)\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "\n",
    "    def load(self, filename='knowledge_graph.json'):\n",
    "        with open(filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        self.graph = nx.node_link_graph(data)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_res = llm.invoke(new_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_as_dict = output_parser.parse(new_res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'id': '1', 'label': 'KnowledgeGraph'}, {'id': '2', 'label': '__init__'}, {'id': '3', 'label': 'graph'}, {'id': '4', 'label': 'nx.Graph()'}, {'id': '5', 'label': 'add_entity'}, {'id': '6', 'label': 'entity'}, {'id': '7', 'label': 'self.graph.add_node(entity)'}, {'id': '8', 'label': 'add_relationship'}, {'id': '9', 'label': 'entity1'}, {'id': '10', 'label': 'entity2'}, {'id': '11', 'label': 'relationship'}, {'id': '12', 'label': 'self.graph.add_edge(entity1, entity2, relationship=relationship)'}, {'id': '13', 'label': 'visualize'}, {'id': '14', 'label': 'filename'}, {'id': '15', 'label': \"'graph.html'\"}, {'id': '16', 'label': 'net'}, {'id': '17', 'label': 'Network(notebook=False)'}, {'id': '18', 'label': 'net.from_nx(self.graph)'}, {'id': '19', 'label': 'net.show(filename, notebook=False)'}, {'id': '20', 'label': 'save'}, {'id': '21', 'label': 'data'}, {'id': '22', 'label': 'nx.node_link_data(self.graph)'}, {'id': '23', 'label': 'f'}, {'id': '24', 'label': 'json.dump(data, f)'}, {'id': '25', 'label': 'load'}, {'id': '26', 'label': 'self.graph = nx.node_link_graph(data)'}], 'edges': [{'source': '1', 'target': '2', 'label': 'has method'}, {'source': '2', 'target': '3', 'label': 'has attribute'}, {'source': '2', 'target': '4', 'label': 'returns'}, {'source': '1', 'target': '5', 'label': 'has method'}, {'source': '5', 'target': '6', 'label': 'has parameter'}, {'source': '5', 'target': '7', 'label': 'returns'}, {'source': '1', 'target': '8', 'label': 'has method'}, {'source': '8', 'target': '9', 'label': 'has parameter'}, {'source': '8', 'target': '10', 'label': 'has parameter'}, {'source': '8', 'target': '11', 'label': 'has parameter'}, {'source': '8', 'target': '12', 'label': 'returns'}, {'source': '1', 'target': '13', 'label': 'has method'}, {'source': '13', 'target': '14', 'label': 'has parameter'}, {'source': '13', 'target': '15', 'label': 'has parameter'}, {'source': '13', 'target': '16', 'label': 'has attribute'}, {'source': '13', 'target': '17', 'label': 'returns'}, {'source': '13', 'target': '18', 'label': 'has attribute'}, {'source': '13', 'target': '19', 'label': 'returns'}, {'source': '1', 'target': '20', 'label': 'has method'}, {'source': '20', 'target': '14', 'label': 'has parameter'}, {'source': '20', 'target': '15', 'label': 'has parameter'}, {'source': '20', 'target': '21', 'label': 'has attribute'}, {'source': '20', 'target': '22', 'label': 'returns'}, {'source': '20', 'target': '23', 'label': 'has attribute'}, {'source': '20', 'target': '24', 'label': 'returns'}, {'source': '1', 'target': '25', 'label': 'has method'}, {'source': '25', 'target': '14', 'label': 'has parameter'}, {'source': '25', 'target': '15', 'label': 'has parameter'}, {'source': '25', 'target': '21', 'label': 'has attribute'}, {'source': '25', 'target': '26', 'label': 'returns'}]}\n"
     ]
    }
   ],
   "source": [
    "print(res_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(res_as_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': '1', 'label': 'Entity'}, {'id': '2', 'label': 'name'}, {'id': '3', 'label': 'Relation'}, {'id': '4', 'label': 'entity1'}, {'id': '5', 'label': 'relationship'}, {'id': '6', 'label': 'entity2'}, {'id': '7', 'label': 'ExtractedData'}, {'id': '8', 'label': 'entities'}, {'id': '9', 'label': 'relations'}]\n"
     ]
    }
   ],
   "source": [
    "print(res_as_dict['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\divya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class GraphRetriever(BaseRetriever):\n",
    "    def __init__(self, graph, embedder, depth=3):\n",
    "        self.graph = graph\n",
    "        self.embedder = embedder\n",
    "        self.depth = depth\n",
    "\n",
    "    def get_relevant_documents(self, query):\n",
    "        # Embed the query\n",
    "        query_embedding = self.embedder.encode(query)\n",
    "\n",
    "        # Find the most similar node to the query\n",
    "        similarities = []\n",
    "        for node, data in self.graph.nodes(data=True):\n",
    "            node_text = f\"{data['label']} (ID: {node})\"\n",
    "            node_embedding = self.embedder.encode(node_text)\n",
    "            similarity = np.dot(query_embedding, node_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(node_embedding))\n",
    "            similarities.append((node, similarity))\n",
    "\n",
    "        # Sort nodes by similarity\n",
    "        sorted_nodes = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get subgraph and create documents\n",
    "        documents = []\n",
    "        for start_node, _ in sorted_nodes[:3]:  # Consider top 3 most similar nodes\n",
    "            subgraph = nx.ego_graph(self.graph, start_node, radius=self.depth)\n",
    "            context = self.subgraph_to_text(subgraph)\n",
    "            documents.append(Document(page_content=context, metadata={\"start_node\": start_node}))\n",
    "\n",
    "        return documents\n",
    "\n",
    "    def subgraph_to_text(self, subgraph):\n",
    "        text = \"\"\n",
    "        for node, data in subgraph.nodes(data=True):\n",
    "            text += f\"Node: {data['label']} (ID: {node})\\n\"\n",
    "            for neighbor in subgraph.neighbors(node):\n",
    "                edge_data = subgraph[node][neighbor]\n",
    "                text += f\"  - {edge_data['label']} -> {subgraph.nodes[neighbor]['label']} (ID: {neighbor})\\n\"\n",
    "        return text\n",
    "\n",
    "class GraphRAG:\n",
    "    def __init__(self, graph_data):\n",
    "        self.graph = self.create_graph(graph_data)\n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.vector_store = None\n",
    "        self.qa_chain = None\n",
    "        self.graph_retriever = GraphRetriever(self.graph, self.embedder)\n",
    "\n",
    "    def create_graph(self, graph_data):\n",
    "        G = nx.Graph()\n",
    "        for node in graph_data['nodes']:\n",
    "            G.add_node(node['id'], label=node['label'])\n",
    "        for edge in graph_data['edges']:\n",
    "            G.add_edge(edge['source'], edge['target'], label=edge['label'])\n",
    "        return G\n",
    "\n",
    "    def create_embeddings(self):\n",
    "        node_texts = [f\"{data['label']} (ID: {node})\" for node, data in self.graph.nodes(data=True)]\n",
    "        edge_texts = [f\"{self.graph.nodes[edge[0]]['label']} - {edge[2]['label']} - {self.graph.nodes[edge[1]]['label']}\" \n",
    "                      for edge in self.graph.edges(data=True)]\n",
    "        all_texts = node_texts + edge_texts\n",
    "        embeddings = self.embedder.encode(all_texts)\n",
    "        return all_texts, embeddings\n",
    "\n",
    "    def create_vector_store(self):\n",
    "        texts, embeddings = self.create_embeddings()\n",
    "        self.vector_store = FAISS.from_embeddings(\n",
    "            text_embeddings=list(zip(texts, embeddings)),\n",
    "            embedding=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "        )\n",
    "\n",
    "    def setup_qa_chain(self):\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            temperature=0.3,\n",
    "            max_tokens=None,\n",
    "            max_retries=2,\n",
    "            tiemout = 15\n",
    "        )\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(\n",
    "            llm=llm,\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=self.graph_retriever\n",
    "        )\n",
    "\n",
    "    def query(self, question):\n",
    "        if not self.qa_chain:\n",
    "            raise ValueError(\"QA chain not set up. Call setup_qa_chain() first.\")\n",
    "        return self.qa_chain.run(question)\n",
    "\n",
    "    def get_subgraph(self, center_node, depth=3):\n",
    "        subgraph_nodes = nx.ego_graph(self.graph, center_node, radius=depth)\n",
    "        return self.graph.subgraph(subgraph_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "graph_data = res_as_dict\n",
    "graph_rag = GraphRAG(graph_data)\n",
    "graph_rag.create_vector_store()\n",
    "graph_rag.setup_qa_chain()\n",
    "\n",
    "# Example query\n",
    "question = \"What is the use of KnowledgeGraph Class and how does it functions?\"\n",
    "answer = graph_rag.query(question)\n",
    "print(f\"Q: {question}\\nA: {answer}\")\n",
    "\n",
    "# Get subgraph\n",
    "subgraph = graph_rag.get_subgraph('1', depth=2)\n",
    "print(\"Subgraph nodes:\", subgraph.nodes(data=True))\n",
    "print(\"Subgraph edges:\", subgraph.edges(data=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
